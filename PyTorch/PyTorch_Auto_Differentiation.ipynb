{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nrGGt3TVDrCF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0,\n",
        "                    3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
        "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "t_un = 0.1 * t_u"
      ],
      "metadata": {
        "id": "cCQ2eO_pFZSw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w, b):\n",
        "  return w*t_u+b    "
      ],
      "metadata": {
        "id": "2evAv5Y3Dug3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p-t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "W1L1VJ6iDx8H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad = True)"
      ],
      "metadata": {
        "id": "8zYNrplND5WO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(model(t_u,*params), t_c)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "6iU_K7czEkPP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad"
      ],
      "metadata": {
        "id": "9aujXqYRF2pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04138619-ffe1-480b-ef1b-27a0250c202b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4517.2969,   82.6000])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if params.grad is not None:\n",
        "  params.grad.zero_()"
      ],
      "metadata": {
        "id": "EVxNG15gG8Iy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad"
      ],
      "metadata": {
        "id": "flAwfc4vHBvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5cd364-2b38-4cc3-cb80-0743292ae837"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자동미분을 적용한 훈련 코드\n",
        "n_epochs = 10\n",
        "learning_rate = 0.01\n",
        "def training_loop(n_epoch, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epoch+1):\n",
        "    if params.grad is not None:  # backward 호출전에 적용\n",
        "      params.grad.zero_()\n",
        "    \n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p,t_c)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -= learning_rate*params.grad # 파라메터 조정    \n",
        "    if epoch % 500 == 0:\n",
        "      print(f\"epoch:{epoch} loss : {float(loss)}\")\n",
        "  return params"
      ],
      "metadata": {
        "id": "3U89picIHJBx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(n_epoch=5000,learning_rate=0.01,params = torch.tensor([1.0,0.0], requires_grad=True),\n",
        "    t_u=t_un, t_c=t_c)  # 마지막 t_u 를 정규화 하지 않으면 큰 값이 나와서 nan이 된다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N-xFwwwIQAv",
        "outputId": "16a17c05-19d2-42d5-e172-334be3469642"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:500 loss : 7.860115051269531\n",
            "epoch:1000 loss : 3.828537940979004\n",
            "epoch:1500 loss : 3.092191219329834\n",
            "epoch:2000 loss : 2.957697868347168\n",
            "epoch:2500 loss : 2.933133840560913\n",
            "epoch:3000 loss : 2.9286484718322754\n",
            "epoch:3500 loss : 2.9278297424316406\n",
            "epoch:4000 loss : 2.9276793003082275\n",
            "epoch:4500 loss : 2.927651882171631\n",
            "epoch:5000 loss : 2.9276468753814697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저는 zero_grad()와 step 이라는 두가지 메소드를 제공\n",
        "# zero_grad는 옵티마이저 생성자에 전달된 파라미터의 모든 grad 속성을 0으로 만든다\n",
        "# step은 옵티마이저 별로 구현된 최적화 전략에 따라서 파라미터 값을 조정"
      ],
      "metadata": {
        "id": "3blFOmIkLMTy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경사하강 옵티마이저\n",
        "import torch.optim as optim\n",
        "\n",
        "params = torch.tensor([1.0,0.0], requires_grad = True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr = learning_rate)"
      ],
      "metadata": {
        "id": "6BtPjANEL6xC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_p = model(t_u, *params)\n",
        "loss = loss_fn(t_p,t_c)\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEIz734aJH02",
        "outputId": "0d08e602-c495-4ebb-93d8-daf584e12fe5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0,0.0],requires_grad = True)\n",
        "learning_rate = 1e-2\n",
        "optimzer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "t_p = model(t_un, *params)\n",
        "loss = loss_fn(t_p,t_c)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RXxPBidQjjZ",
        "outputId": "f348bd7b-6ad7-476d-a5a6-b2ef1e41d200"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자동미분과 Opimizer을 적용한 훈련 코드\n",
        "def training_loop(n_epoch, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epoch + 1):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p,t_c)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f\"epoch:{epoch} loss:{float(loss)}\")\n",
        "  return params"
      ],
      "metadata": {
        "id": "LOL72F43RZ5H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_loop(n_epoch=5000, optimizer=optimizer, params=params, t_u = t_un, t_c= t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtxJ0IW2YRpL",
        "outputId": "d3d4e236-9415-4490-e118-1ad8834a864c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:500 loss:7.860119819641113\n",
            "epoch:1000 loss:3.828537940979004\n",
            "epoch:1500 loss:3.092191219329834\n",
            "epoch:2000 loss:2.957697868347168\n",
            "epoch:2500 loss:2.933133840560913\n",
            "epoch:3000 loss:2.9286484718322754\n",
            "epoch:3500 loss:2.9278297424316406\n",
            "epoch:4000 loss:2.9276793003082275\n",
            "epoch:4500 loss:2.927651882171631\n",
            "epoch:5000 loss:2.9276468753814697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam([params], lr = learning_rate)\n",
        "\n",
        "training_loop(n_epoch=5000, optimizer=optimizer, params=params, t_u = t_un, t_c= t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f94d8FjSPTg",
        "outputId": "142df673-c9b1-47fb-dbca-a01c00b7b593"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:500 loss:2.927645206451416\n",
            "epoch:1000 loss:2.927645206451416\n",
            "epoch:1500 loss:2.927645206451416\n",
            "epoch:2000 loss:2.927645683288574\n",
            "epoch:2500 loss:2.927644968032837\n",
            "epoch:3000 loss:2.927645206451416\n",
            "epoch:3500 loss:2.9276459217071533\n",
            "epoch:4000 loss:2.9276702404022217\n",
            "epoch:4500 loss:2.9276463985443115\n",
            "epoch:5000 loss:2.9276459217071533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3677, -17.3048], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randperm함수\n",
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2*n_samples)\n",
        "shuffled_indicies =  torch.randperm(n_samples)\n",
        "\n",
        "train_indicies = shuffled_indicies[:-n_val]\n",
        "val_indicies = shuffled_indicies[-n_val:]\n",
        "\n",
        "train_indicies, val_indicies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XIuAxR_Sd20",
        "outputId": "5254cd01-5249-4202-c0a4-d2e054a70a2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2, 10,  3,  8,  7,  1,  5,  6,  0]), tensor([9, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련셋, 검증셋\n",
        "train_t_u = t_u[train_indicies]\n",
        "train_t_c = t_c[train_indicies]\n",
        "\n",
        "val_t_u = t_u[val_indicies]\n",
        "val_t_c = t_c[val_indicies]\n",
        "\n",
        "train_t_un = 0.1*train_t_u\n",
        "val_t_un = 0.1*val_t_u"
      ],
      "metadata": {
        "id": "_07UUzdRTK6v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 자동미분 옵티마이저를 적용한 훈련 코드\n",
        "# 과적합 여부를 판단하기 위해서 검증셋에 대한 손실 값을 계산\n",
        "def training_loop(n_epoch, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epoch+1):        \n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p,train_t_c)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p,val_t_c)\n",
        "\n",
        "    optimizer.zero_grad()    \n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 500 == 0:\n",
        "      print(f\"epoch:{epoch} train loss : {float(train_loss)} validation loss : {float(val_loss)}\")\n",
        "  return params"
      ],
      "metadata": {
        "id": "GJxhD4h3UcRg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD([params], lr = learning_rate)\n",
        "\n",
        "training_loop(n_epoch=8000, optimizer=optimizer, params=params\n",
        "              , train_t_u=train_t_u, val_t_u=val_t_u, train_t_c=train_t_c, val_t_c=val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gkBXjLkVpUg",
        "outputId": "d57f9fa8-495d-407c-9dbd-2a73ec4feb4a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:500 train loss : 34.17964172363281 validation loss : 4.039036750793457\n",
            "epoch:1000 train loss : 33.510498046875 validation loss : 4.057750225067139\n",
            "epoch:1500 train loss : 32.85545349121094 validation loss : 4.0764384269714355\n",
            "epoch:2000 train loss : 32.21421813964844 validation loss : 4.095090866088867\n",
            "epoch:2500 train loss : 31.586503982543945 validation loss : 4.1137166023254395\n",
            "epoch:3000 train loss : 30.972002029418945 validation loss : 4.132303237915039\n",
            "epoch:3500 train loss : 30.370466232299805 validation loss : 4.150845050811768\n",
            "epoch:4000 train loss : 29.78160285949707 validation loss : 4.1693501472473145\n",
            "epoch:4500 train loss : 29.20513916015625 validation loss : 4.187798500061035\n",
            "epoch:5000 train loss : 28.640830993652344 validation loss : 4.206206321716309\n",
            "epoch:5500 train loss : 28.08842658996582 validation loss : 4.224564075469971\n",
            "epoch:6000 train loss : 27.54765510559082 validation loss : 4.2428669929504395\n",
            "epoch:6500 train loss : 27.01827621459961 validation loss : 4.261116027832031\n",
            "epoch:7000 train loss : 26.50006103515625 validation loss : 4.27930212020874\n",
            "epoch:7500 train loss : 25.99275779724121 validation loss : 4.297427654266357\n",
            "epoch:8000 train loss : 25.49615478515625 validation loss : 4.315489768981934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2876, -2.7472], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}