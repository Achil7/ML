{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f2ca3a",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론 프로그래밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b8c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier # 다층 퍼셉트론\n",
    "from sklearn.model_selection import train_test_split # 학습데이터와 검증 데이터를 구분\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b09155",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = datasets.load_digits()\n",
    "x_train, x_test, y_train, y_test = train_test_split(digit.data, digit.target, test_size = 0.3, random_state = 32) # 7:3으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1180db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 분류기 학습\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (100), learning_rate_init=0.001,\n",
    "                    batch_size = 32, max_iter = 300 # 최대 300번까지 학습이지만 그전에 최적화 되면 stop\n",
    "                   , solver = 'sgd', verbose = True) # verbose : 학습과정을 보여줌(디폴트는 False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71cf991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.89129402\n",
      "Iteration 2, loss = 0.29781083\n",
      "Iteration 3, loss = 0.19976415\n",
      "Iteration 4, loss = 0.14876073\n",
      "Iteration 5, loss = 0.12494284\n",
      "Iteration 6, loss = 0.10421923\n",
      "Iteration 7, loss = 0.09342525\n",
      "Iteration 8, loss = 0.08204918\n",
      "Iteration 9, loss = 0.07446860\n",
      "Iteration 10, loss = 0.06514663\n",
      "Iteration 11, loss = 0.05968044\n",
      "Iteration 12, loss = 0.05763656\n",
      "Iteration 13, loss = 0.05187656\n",
      "Iteration 14, loss = 0.04855765\n",
      "Iteration 15, loss = 0.04423666\n",
      "Iteration 16, loss = 0.03994728\n",
      "Iteration 17, loss = 0.03754712\n",
      "Iteration 18, loss = 0.03501431\n",
      "Iteration 19, loss = 0.03416103\n",
      "Iteration 20, loss = 0.03161469\n",
      "Iteration 21, loss = 0.03022751\n",
      "Iteration 22, loss = 0.02729125\n",
      "Iteration 23, loss = 0.02856543\n",
      "Iteration 24, loss = 0.02629268\n",
      "Iteration 25, loss = 0.02451510\n",
      "Iteration 26, loss = 0.02257927\n",
      "Iteration 27, loss = 0.02231760\n",
      "Iteration 28, loss = 0.02083924\n",
      "Iteration 29, loss = 0.02007392\n",
      "Iteration 30, loss = 0.01931455\n",
      "Iteration 31, loss = 0.01859597\n",
      "Iteration 32, loss = 0.01775915\n",
      "Iteration 33, loss = 0.01759438\n",
      "Iteration 34, loss = 0.01656695\n",
      "Iteration 35, loss = 0.01736826\n",
      "Iteration 36, loss = 0.01610094\n",
      "Iteration 37, loss = 0.01516692\n",
      "Iteration 38, loss = 0.01501979\n",
      "Iteration 39, loss = 0.01463454\n",
      "Iteration 40, loss = 0.01385307\n",
      "Iteration 41, loss = 0.01351857\n",
      "Iteration 42, loss = 0.01324746\n",
      "Iteration 43, loss = 0.01293833\n",
      "Iteration 44, loss = 0.01244919\n",
      "Iteration 45, loss = 0.01191898\n",
      "Iteration 46, loss = 0.01185362\n",
      "Iteration 47, loss = 0.01157167\n",
      "Iteration 48, loss = 0.01106756\n",
      "Iteration 49, loss = 0.01099238\n",
      "Iteration 50, loss = 0.01041581\n",
      "Iteration 51, loss = 0.01033481\n",
      "Iteration 52, loss = 0.01009259\n",
      "Iteration 53, loss = 0.00980559\n",
      "Iteration 54, loss = 0.00976593\n",
      "Iteration 55, loss = 0.00937090\n",
      "Iteration 56, loss = 0.00927445\n",
      "Iteration 57, loss = 0.00921073\n",
      "Iteration 58, loss = 0.00913708\n",
      "Iteration 59, loss = 0.00870491\n",
      "Iteration 60, loss = 0.00858873\n",
      "Iteration 61, loss = 0.00840305\n",
      "Iteration 62, loss = 0.00834066\n",
      "Iteration 63, loss = 0.00813367\n",
      "Iteration 64, loss = 0.00807265\n",
      "Iteration 65, loss = 0.00783851\n",
      "Iteration 66, loss = 0.00777889\n",
      "Iteration 67, loss = 0.00758117\n",
      "Iteration 68, loss = 0.00764120\n",
      "Iteration 69, loss = 0.00724491\n",
      "Iteration 70, loss = 0.00713227\n",
      "Iteration 71, loss = 0.00703824\n",
      "Iteration 72, loss = 0.00682810\n",
      "Iteration 73, loss = 0.00694630\n",
      "Iteration 74, loss = 0.00682794\n",
      "Iteration 75, loss = 0.00669743\n",
      "Iteration 76, loss = 0.00662553\n",
      "Iteration 77, loss = 0.00646784\n",
      "Iteration 78, loss = 0.00634628\n",
      "Iteration 79, loss = 0.00627075\n",
      "Iteration 80, loss = 0.00615293\n",
      "Iteration 81, loss = 0.00599551\n",
      "Iteration 82, loss = 0.00592259\n",
      "Iteration 83, loss = 0.00590837\n",
      "Iteration 84, loss = 0.00583298\n",
      "Iteration 85, loss = 0.00574698\n",
      "Iteration 86, loss = 0.00569579\n",
      "Iteration 87, loss = 0.00559518\n",
      "Iteration 88, loss = 0.00553869\n",
      "Iteration 89, loss = 0.00542513\n",
      "Iteration 90, loss = 0.00545917\n",
      "Iteration 91, loss = 0.00532053\n",
      "Iteration 92, loss = 0.00533497\n",
      "Iteration 93, loss = 0.00518136\n",
      "Iteration 94, loss = 0.00512157\n",
      "Iteration 95, loss = 0.00510851\n",
      "Iteration 96, loss = 0.00499911\n",
      "Iteration 97, loss = 0.00491654\n",
      "Iteration 98, loss = 0.00485788\n",
      "Iteration 99, loss = 0.00495237\n",
      "Iteration 100, loss = 0.00482618\n",
      "Iteration 101, loss = 0.00474855\n",
      "Iteration 102, loss = 0.00473425\n",
      "Iteration 103, loss = 0.00464218\n",
      "Iteration 104, loss = 0.00461916\n",
      "Iteration 105, loss = 0.00453334\n",
      "Iteration 106, loss = 0.00448985\n",
      "Iteration 107, loss = 0.00451224\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=32, hidden_layer_sizes=100, max_iter=300, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=32, hidden_layer_sizes=100, max_iter=300, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(batch_size=32, hidden_layer_sizes=100, max_iter=300, solver='sgd',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d5a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851851851851852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "predict = mlp.predict(x_test)\n",
    "mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fc1956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0., 56.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 45.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 74.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 50.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., 57.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., 57.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 53.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., 37.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1., 55.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혼돈행렬\n",
    "conf = np.zeros((10,10))\n",
    "for i in range(len(predict)):\n",
    "    conf[predict[i], y_test[i]] += 1\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da09346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851851851851852"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([conf[i,i] for i in range(len(conf))]) / len(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b390d87",
   "metadata": {},
   "source": [
    "- 퍼셉트론 < 다층퍼셉트론 < svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006534f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e92f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화소수가 많은 MNIST 데이터 셋으로 확장\n",
    "# 8 x 8 -> 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8b0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋을 다층 퍼셉트론으로 인식\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c82a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38e4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋 읽기\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84a620fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172594ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac590ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data\n",
    "Y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab370e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01f2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.3, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a137bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100), learning_rate_init=0.001\n",
    "             ,batch_size = 512, max_iter = 300, solver = 'adam', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c853b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 5.73996526\n",
      "Iteration 2, loss = 1.88011007\n",
      "Iteration 3, loss = 1.25126958\n",
      "Iteration 4, loss = 0.90506720\n",
      "Iteration 5, loss = 0.68427842\n",
      "Iteration 6, loss = 0.52592613\n",
      "Iteration 7, loss = 0.41579753\n",
      "Iteration 8, loss = 0.33382644\n",
      "Iteration 9, loss = 0.27173203\n",
      "Iteration 10, loss = 0.22790534\n",
      "Iteration 11, loss = 0.18241951\n",
      "Iteration 12, loss = 0.14851019\n",
      "Iteration 13, loss = 0.12602128\n",
      "Iteration 14, loss = 0.10923751\n",
      "Iteration 15, loss = 0.10453139\n",
      "Iteration 16, loss = 0.08592386\n",
      "Iteration 17, loss = 0.07385869\n",
      "Iteration 18, loss = 0.06344919\n",
      "Iteration 19, loss = 0.05457604\n",
      "Iteration 20, loss = 0.04962246\n",
      "Iteration 21, loss = 0.04714802\n",
      "Iteration 22, loss = 0.04827988\n",
      "Iteration 23, loss = 0.04724158\n",
      "Iteration 24, loss = 0.05061021\n",
      "Iteration 25, loss = 0.04264600\n",
      "Iteration 26, loss = 0.04349129\n",
      "Iteration 27, loss = 0.04458033\n",
      "Iteration 28, loss = 0.04068405\n",
      "Iteration 29, loss = 0.04291117\n",
      "Iteration 30, loss = 0.04930763\n",
      "Iteration 31, loss = 0.05364076\n",
      "Iteration 32, loss = 0.03883909\n",
      "Iteration 33, loss = 0.04253906\n",
      "Iteration 34, loss = 0.04149538\n",
      "Iteration 35, loss = 0.04447611\n",
      "Iteration 36, loss = 0.06260752\n",
      "Iteration 37, loss = 0.04955134\n",
      "Iteration 38, loss = 0.05264887\n",
      "Iteration 39, loss = 0.04091307\n",
      "Iteration 40, loss = 0.04601531\n",
      "Iteration 41, loss = 0.03246985\n",
      "Iteration 42, loss = 0.04334920\n",
      "Iteration 43, loss = 0.04421098\n",
      "Iteration 44, loss = 0.03821345\n",
      "Iteration 45, loss = 0.03686448\n",
      "Iteration 46, loss = 0.04407313\n",
      "Iteration 47, loss = 0.03521317\n",
      "Iteration 48, loss = 0.03977670\n",
      "Iteration 49, loss = 0.03774836\n",
      "Iteration 50, loss = 0.03759630\n",
      "Iteration 51, loss = 0.04355311\n",
      "Iteration 52, loss = 0.03702719\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=512, hidden_layer_sizes=100, max_iter=300,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=512, hidden_layer_sizes=100, max_iter=300,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(batch_size=512, hidden_layer_sizes=100, max_iter=300,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406f0ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6', '9', '2', ..., '3', '5', '7'], dtype='<U1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = mlp.predict(x_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d9200e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9553809523809523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f023870",
   "metadata": {},
   "source": [
    "### 하이퍼 매개변수의 값을 결정하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abdd90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_layer_sizes = (100)     100개의 노드를 가지는 히든 레이어 한개 층을 둔다\n",
    "# hidden_layer_sizes = (100,80)\n",
    "# learning_rate_init = 0.001     학습률 p = 0.001\n",
    "# batch_size = 32               미니배치 크기를 32로 설정\n",
    "# max_iter = 300               최대 epoch수를 300\n",
    "# solv = ' sgd'최적화 알고리즘(옵티마이져) 스토캐스틱 경사하강법\n",
    "# n_jobs = 코어 개수에 따른 코어 사용개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d681297",
   "metadata": {},
   "source": [
    "- 학습을 중간에 멈춘 이유 n_iter_no_change = 10 10세대 동안 손실함수 감소량이 tol = 0.0001   0.0001이하면 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355e291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad2d0244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664706845.4968677"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a228010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오래걸림\n",
    "# start = time.time()\n",
    "# mlp = MLPClassifier(learning_rate_init = 0.001, batch_size = 32, max_iter = 300, solver = 'sgd')\n",
    "# prange = range(50,1001,50)\n",
    "# train_score, test_score =  validation_curve(mlp, x_train, y_train, param_name = 'hidden_layer_sizes'\n",
    "#                                     ,param_range = prange,cv = 10, scoring = 'accuracy', n_jobs = 4, verbose = True)\n",
    "# end = time.time()\n",
    "# print(f\"하이퍼 매개변수 최적화에 걸린시간은 {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a038cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mean = np.mean(train_score, axis = 1)\n",
    "# train_std = np.std(train_score, axis = 1)\n",
    "# test_mean = np.mean(train_score, axis = 1)\n",
    "# test_std = np.std(train_score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6cad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_numbers_nodes = prange[np.argmax(test_mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "559241d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_numbers_nodes 으로 모델링해서 결과를 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
